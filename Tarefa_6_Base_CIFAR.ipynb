{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa_6_Base_CIFAR",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeansds/Curso_Udemy---Deep-Learning-com-Python-de-A-a-Z/blob/master/Tarefa_6_Base_CIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGXQiDQaQlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVRqAE3Fbqem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2hhofc8aquf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "previsores = x_train\n",
        "previsores = previsores.astype('float32')\n",
        "previsores /= 255\n",
        "classe = np_utils.to_categorical(y_train, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-kEQeaZdaI6",
        "colab_type": "code",
        "outputId": "c7d03d2f-11fb-4eec-e9cb-891dfe72cf3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
        "resultados = []\n",
        "for indice_treinamento, indice_teste in kfold.split(previsores, np.zeros(shape = (classe.shape[0], 1))):\n",
        "  #print(indice_treinamento, 'Treinamento', indice_teste, 'Teste')\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "  model.fit(previsores[indice_treinamento], classe[indice_treinamento], batch_size = 128,\n",
        "                    epochs = 20)\n",
        "  precisao = model.evaluate(previsores[indice_teste], classe[indice_teste])\n",
        "  resultados.append(precisao[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "45000/45000 [==============================] - 20s 451us/step - loss: 1.6306 - acc: 0.4003\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.2399 - acc: 0.5580\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.0730 - acc: 0.6196\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.9668 - acc: 0.6586\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.8791 - acc: 0.6904\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.8142 - acc: 0.7139\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7677 - acc: 0.7291\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7203 - acc: 0.7464\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.6794 - acc: 0.7614\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6415 - acc: 0.7737\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.6198 - acc: 0.7807\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5885 - acc: 0.7922\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5630 - acc: 0.8017\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5400 - acc: 0.8067\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5188 - acc: 0.8159\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4977 - acc: 0.8199\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4813 - acc: 0.8308\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4612 - acc: 0.8368\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4488 - acc: 0.8387\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4285 - acc: 0.8455\n",
            "5000/5000 [==============================] - 1s 111us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 147us/step - loss: 1.6311 - acc: 0.4024\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.2117 - acc: 0.5673\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.0091 - acc: 0.6429\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.9030 - acc: 0.6826\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.8181 - acc: 0.7122\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7602 - acc: 0.7323\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.7099 - acc: 0.7517\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6678 - acc: 0.7659\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.6328 - acc: 0.7792\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.6001 - acc: 0.7882\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5736 - acc: 0.7957\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5445 - acc: 0.8092\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5251 - acc: 0.8144\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4970 - acc: 0.8234\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.4827 - acc: 0.8297\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.4603 - acc: 0.8370\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4424 - acc: 0.8434\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4237 - acc: 0.8489\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.4132 - acc: 0.8538\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.3965 - acc: 0.8570\n",
            "5000/5000 [==============================] - 1s 105us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 147us/step - loss: 1.6406 - acc: 0.3950\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 1.2570 - acc: 0.5496\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 1.0809 - acc: 0.6158\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.9574 - acc: 0.6598\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.8861 - acc: 0.6889\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8174 - acc: 0.7125\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7546 - acc: 0.7344\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7126 - acc: 0.7447\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.6736 - acc: 0.7615\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.6376 - acc: 0.7737\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.6034 - acc: 0.7869\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5782 - acc: 0.7955\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.5540 - acc: 0.8033\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.5275 - acc: 0.8133\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.5039 - acc: 0.8202\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4812 - acc: 0.8302\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4673 - acc: 0.8321\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4500 - acc: 0.8393\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 140us/step - loss: 0.4342 - acc: 0.8451\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 140us/step - loss: 0.4129 - acc: 0.8515\n",
            "5000/5000 [==============================] - 1s 113us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 153us/step - loss: 1.6379 - acc: 0.3968\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 1.2223 - acc: 0.5610\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.0182 - acc: 0.6410\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 140us/step - loss: 0.9112 - acc: 0.6790\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 141us/step - loss: 0.8257 - acc: 0.7107\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 141us/step - loss: 0.7629 - acc: 0.7321\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 140us/step - loss: 0.7232 - acc: 0.7467\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.6764 - acc: 0.7644\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.6355 - acc: 0.7744\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6066 - acc: 0.7857\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5779 - acc: 0.7961\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5533 - acc: 0.8045\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5191 - acc: 0.8158\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5055 - acc: 0.8209\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4834 - acc: 0.8304\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4609 - acc: 0.8351\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4474 - acc: 0.8396\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4308 - acc: 0.8479\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4166 - acc: 0.8525\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4084 - acc: 0.8528\n",
            "5000/5000 [==============================] - 1s 123us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 155us/step - loss: 1.6222 - acc: 0.4029\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 1.2443 - acc: 0.5539\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.0716 - acc: 0.6210\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.9469 - acc: 0.6672\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.8684 - acc: 0.6927\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.8013 - acc: 0.7171\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7529 - acc: 0.7374\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7084 - acc: 0.7517\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6687 - acc: 0.7646\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.6366 - acc: 0.7765\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.6097 - acc: 0.7873\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.5763 - acc: 0.7951\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.5492 - acc: 0.8054\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.5359 - acc: 0.8098\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 141us/step - loss: 0.5046 - acc: 0.8209\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 141us/step - loss: 0.4855 - acc: 0.8284\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 141us/step - loss: 0.4754 - acc: 0.8307\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.4569 - acc: 0.8379\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4433 - acc: 0.8406\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4230 - acc: 0.8493\n",
            "5000/5000 [==============================] - 1s 129us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 157us/step - loss: 1.6694 - acc: 0.3855\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.2436 - acc: 0.5543\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 1.0697 - acc: 0.6239\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.9612 - acc: 0.6602\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8745 - acc: 0.6915\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8183 - acc: 0.7119\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.7624 - acc: 0.7334\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.7159 - acc: 0.7488\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.6836 - acc: 0.7577\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.6357 - acc: 0.7746\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.6140 - acc: 0.7818\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.5906 - acc: 0.7928\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.5482 - acc: 0.8048\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.5314 - acc: 0.8119\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 139us/step - loss: 0.5084 - acc: 0.8192\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4947 - acc: 0.8234\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4760 - acc: 0.8297\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4577 - acc: 0.8381\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4371 - acc: 0.8443\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4248 - acc: 0.8486\n",
            "5000/5000 [==============================] - 1s 136us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 157us/step - loss: 1.6501 - acc: 0.3901\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 1.2549 - acc: 0.5502\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.0649 - acc: 0.6238\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.9318 - acc: 0.6705\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8433 - acc: 0.7027\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.7807 - acc: 0.7245\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7279 - acc: 0.7440\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.6847 - acc: 0.7596\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.6438 - acc: 0.7764\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6117 - acc: 0.7844\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5779 - acc: 0.7961\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5528 - acc: 0.8048\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5284 - acc: 0.8141\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5012 - acc: 0.8226\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4926 - acc: 0.8251\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4670 - acc: 0.8334\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4427 - acc: 0.8421\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4330 - acc: 0.8455\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4083 - acc: 0.8535\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4027 - acc: 0.8567\n",
            "5000/5000 [==============================] - 1s 145us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 158us/step - loss: 1.6285 - acc: 0.4041\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 1.2278 - acc: 0.5610\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 1.0502 - acc: 0.6293\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.9351 - acc: 0.6722\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.8485 - acc: 0.7023\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.7795 - acc: 0.7257\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7297 - acc: 0.7430\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6938 - acc: 0.7576\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6516 - acc: 0.7722\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6142 - acc: 0.7833\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5814 - acc: 0.7940\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5514 - acc: 0.8059\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5296 - acc: 0.8122\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.5023 - acc: 0.8218\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 133us/step - loss: 0.4767 - acc: 0.8303\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4661 - acc: 0.8341\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4519 - acc: 0.8402\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.4254 - acc: 0.8460\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.4148 - acc: 0.8507\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.3994 - acc: 0.8571\n",
            "5000/5000 [==============================] - 1s 155us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 162us/step - loss: 1.6581 - acc: 0.3926\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.2721 - acc: 0.5443\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 1.1011 - acc: 0.6109\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.9988 - acc: 0.6497\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.9044 - acc: 0.6828\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8511 - acc: 0.6999\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8012 - acc: 0.7174\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7391 - acc: 0.7405\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.7099 - acc: 0.7515\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.6748 - acc: 0.7628\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.6471 - acc: 0.7705\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.6182 - acc: 0.7826\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5944 - acc: 0.7903\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5665 - acc: 0.8006\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5548 - acc: 0.8030\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.5271 - acc: 0.8115\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5151 - acc: 0.8169\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5031 - acc: 0.8209\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4785 - acc: 0.8316\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 138us/step - loss: 0.4700 - acc: 0.8325\n",
            "5000/5000 [==============================] - 1s 158us/step\n",
            "Epoch 1/20\n",
            "45000/45000 [==============================] - 7s 165us/step - loss: 1.6636 - acc: 0.3900\n",
            "Epoch 2/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 1.2726 - acc: 0.5434\n",
            "Epoch 3/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 1.0906 - acc: 0.6124\n",
            "Epoch 4/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.9789 - acc: 0.6552\n",
            "Epoch 5/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.8882 - acc: 0.6893\n",
            "Epoch 6/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.8318 - acc: 0.7076\n",
            "Epoch 7/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.7712 - acc: 0.7284\n",
            "Epoch 8/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.7271 - acc: 0.7445\n",
            "Epoch 9/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.6941 - acc: 0.7562\n",
            "Epoch 10/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.6513 - acc: 0.7706\n",
            "Epoch 11/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.6296 - acc: 0.7803\n",
            "Epoch 12/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.6001 - acc: 0.7880\n",
            "Epoch 13/20\n",
            "45000/45000 [==============================] - 6s 135us/step - loss: 0.5863 - acc: 0.7936\n",
            "Epoch 14/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.5513 - acc: 0.8030\n",
            "Epoch 15/20\n",
            "45000/45000 [==============================] - 6s 142us/step - loss: 0.5353 - acc: 0.8096\n",
            "Epoch 16/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.5120 - acc: 0.8207\n",
            "Epoch 17/20\n",
            "45000/45000 [==============================] - 6s 136us/step - loss: 0.4953 - acc: 0.8244\n",
            "Epoch 18/20\n",
            "45000/45000 [==============================] - 6s 134us/step - loss: 0.4731 - acc: 0.8306\n",
            "Epoch 19/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4559 - acc: 0.8366\n",
            "Epoch 20/20\n",
            "45000/45000 [==============================] - 6s 137us/step - loss: 0.4520 - acc: 0.8374\n",
            "5000/5000 [==============================] - 1s 170us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRwyX8GnfwjR",
        "colab_type": "code",
        "outputId": "e30dfc40-d75a-4f73-cf4d-0a9d4a7fbbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(resultados)\n",
        "print(sum(resultados)/ len(resultados))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7952, 0.7846, 0.7946, 0.799, 0.79, 0.7976, 0.7952, 0.808, 0.7842, 0.7952]\n",
            "0.7943600000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgWMUEbe5yP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagem_teste = np.expand_dims(x_test[1], axis = 0)# adiciona uma coluna, a img Ã© 64, 64, 3, com isto ela vira 1, 64, 64, 3 pois o tensor flow precisa deste formato para funcionar\n",
        "print(model.predict(imagem_teste))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}