{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa_8_Classificador_Bart_Homer",
      "provenance": [],
      "authorship_tag": "ABX9TyPVOgZCyB7mglZpU+ufJunP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeansds/Curso_Udemy---Deep-Learning-com-Python-de-A-a-Z/blob/master/Tarefa_8_Classificador_Bart_Homer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsrGSUVRhC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1ad72c0b-1242-41d3-c067-aaae5f9c359c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p566heDgSE_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base = pd.read_csv('/content/sample_data/original.csv')\n",
        "previsores = base.iloc[:, 0:6].values\n",
        "classe = base.iloc[:, 6].values\n",
        "classe = LabelEncoder().fit_transform(classe) # transforma as repostas bart e homer em binarios\n",
        "#print(classe)\n",
        "#print(previsores)\n",
        "X_train, X_test, y_train, y_test = train_test_split(previsores, classe, test_size=0.25, random_state=42)\n",
        "#print(X_train[0])\n",
        "#print(X_test[0])\n",
        "#print(y_train[0])\n",
        "#print(y_test[0])\n",
        "#classe_dummy = np_utils.to_categorical(classe)\n",
        "#print(classe_dummy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXAYY1f4TQvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ca273d0f-de2e-49ee-83ba-7f288faf30a0"
      },
      "source": [
        "classificador = Sequential()\n",
        "classificador.add(Dense(units = 128, activation = 'relu'))\n",
        "classificador.add(Dropout(0.25))\n",
        "\n",
        "classificador.add(Dense(units = 128, activation = 'relu'))\n",
        "classificador.add(Dropout(0.25))\n",
        "\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvGRi9AZHEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43c513f4-e5df-4520-ed7c-cc387efe03ef"
      },
      "source": [
        "classificador.fit(X_train, y_train,\n",
        "                  batch_size = 128, epochs = 100,\n",
        "                  validation_data = (X_test, y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 219 samples, validate on 74 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "219/219 [==============================] - 0s 2ms/step - loss: 0.9655 - acc: 0.3470 - val_loss: 0.7638 - val_acc: 0.3108\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 0s 60us/step - loss: 0.7134 - acc: 0.5068 - val_loss: 0.5299 - val_acc: 0.9054\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 0s 54us/step - loss: 0.5283 - acc: 0.7443 - val_loss: 0.4226 - val_acc: 0.9324\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 0s 53us/step - loss: 0.4254 - acc: 0.8356 - val_loss: 0.3690 - val_acc: 0.9189\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 0s 61us/step - loss: 0.3692 - acc: 0.8721 - val_loss: 0.3347 - val_acc: 0.9189\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 0s 58us/step - loss: 0.3363 - acc: 0.8767 - val_loss: 0.3099 - val_acc: 0.9189\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 0s 66us/step - loss: 0.3027 - acc: 0.8950 - val_loss: 0.2912 - val_acc: 0.9324\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 0s 58us/step - loss: 0.2877 - acc: 0.9041 - val_loss: 0.2767 - val_acc: 0.9324\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 0s 41us/step - loss: 0.2751 - acc: 0.8904 - val_loss: 0.2654 - val_acc: 0.9324\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 0s 39us/step - loss: 0.2570 - acc: 0.9132 - val_loss: 0.2567 - val_acc: 0.8108\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.2495 - acc: 0.8995 - val_loss: 0.2500 - val_acc: 0.7973\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 0s 39us/step - loss: 0.2409 - acc: 0.8904 - val_loss: 0.2446 - val_acc: 0.7973\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 0s 41us/step - loss: 0.2361 - acc: 0.8858 - val_loss: 0.2405 - val_acc: 0.7973\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 0s 38us/step - loss: 0.2298 - acc: 0.8858 - val_loss: 0.2374 - val_acc: 0.7973\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 0s 38us/step - loss: 0.2268 - acc: 0.8813 - val_loss: 0.2350 - val_acc: 0.7973\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 0s 39us/step - loss: 0.2212 - acc: 0.8813 - val_loss: 0.2331 - val_acc: 0.7973\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 0s 41us/step - loss: 0.2167 - acc: 0.8767 - val_loss: 0.2312 - val_acc: 0.7973\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 0s 40us/step - loss: 0.2130 - acc: 0.8813 - val_loss: 0.2296 - val_acc: 0.7838\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 0s 39us/step - loss: 0.2101 - acc: 0.8767 - val_loss: 0.2279 - val_acc: 0.7973\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.2071 - acc: 0.8813 - val_loss: 0.2263 - val_acc: 0.7973\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 0s 58us/step - loss: 0.2078 - acc: 0.8767 - val_loss: 0.2249 - val_acc: 0.7973\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 0s 53us/step - loss: 0.2028 - acc: 0.8813 - val_loss: 0.2239 - val_acc: 0.7973\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.2025 - acc: 0.8767 - val_loss: 0.2226 - val_acc: 0.7973\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.1964 - acc: 0.8721 - val_loss: 0.2212 - val_acc: 0.7973\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 0s 35us/step - loss: 0.1953 - acc: 0.8904 - val_loss: 0.2200 - val_acc: 0.7973\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1966 - acc: 0.8813 - val_loss: 0.2188 - val_acc: 0.7973\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 0s 51us/step - loss: 0.1947 - acc: 0.8950 - val_loss: 0.2173 - val_acc: 0.7973\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1932 - acc: 0.8858 - val_loss: 0.2159 - val_acc: 0.7973\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1913 - acc: 0.8721 - val_loss: 0.2145 - val_acc: 0.7973\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 0s 55us/step - loss: 0.1889 - acc: 0.9041 - val_loss: 0.2132 - val_acc: 0.8243\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1897 - acc: 0.9087 - val_loss: 0.2119 - val_acc: 0.8649\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1895 - acc: 0.9132 - val_loss: 0.2104 - val_acc: 0.9324\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 0s 43us/step - loss: 0.1846 - acc: 0.9132 - val_loss: 0.2096 - val_acc: 0.9189\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.1871 - acc: 0.9087 - val_loss: 0.2086 - val_acc: 0.9324\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 0s 45us/step - loss: 0.1830 - acc: 0.9087 - val_loss: 0.2079 - val_acc: 0.9324\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 0s 45us/step - loss: 0.1835 - acc: 0.9132 - val_loss: 0.2077 - val_acc: 0.9324\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 0s 56us/step - loss: 0.1802 - acc: 0.9224 - val_loss: 0.2075 - val_acc: 0.9324\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 0s 41us/step - loss: 0.1830 - acc: 0.9087 - val_loss: 0.2079 - val_acc: 0.9324\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1799 - acc: 0.9178 - val_loss: 0.2084 - val_acc: 0.9324\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 0s 54us/step - loss: 0.1781 - acc: 0.9361 - val_loss: 0.2093 - val_acc: 0.9189\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 0s 55us/step - loss: 0.1823 - acc: 0.8767 - val_loss: 0.2098 - val_acc: 0.9189\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 0s 51us/step - loss: 0.1776 - acc: 0.9132 - val_loss: 0.2103 - val_acc: 0.9054\n",
            "Epoch 43/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.1772 - acc: 0.9178 - val_loss: 0.2104 - val_acc: 0.9054\n",
            "Epoch 44/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1762 - acc: 0.9132 - val_loss: 0.2105 - val_acc: 0.9054\n",
            "Epoch 45/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1759 - acc: 0.8995 - val_loss: 0.2108 - val_acc: 0.9054\n",
            "Epoch 46/100\n",
            "219/219 [==============================] - 0s 42us/step - loss: 0.1751 - acc: 0.9087 - val_loss: 0.2104 - val_acc: 0.9189\n",
            "Epoch 47/100\n",
            "219/219 [==============================] - 0s 48us/step - loss: 0.1742 - acc: 0.9132 - val_loss: 0.2104 - val_acc: 0.9189\n",
            "Epoch 48/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1722 - acc: 0.9269 - val_loss: 0.2099 - val_acc: 0.9459\n",
            "Epoch 49/100\n",
            "219/219 [==============================] - 0s 51us/step - loss: 0.1742 - acc: 0.9087 - val_loss: 0.2089 - val_acc: 0.9324\n",
            "Epoch 50/100\n",
            "219/219 [==============================] - 0s 43us/step - loss: 0.1724 - acc: 0.9132 - val_loss: 0.2083 - val_acc: 0.9324\n",
            "Epoch 51/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1692 - acc: 0.9178 - val_loss: 0.2082 - val_acc: 0.9324\n",
            "Epoch 52/100\n",
            "219/219 [==============================] - 0s 51us/step - loss: 0.1738 - acc: 0.9041 - val_loss: 0.2082 - val_acc: 0.9324\n",
            "Epoch 53/100\n",
            "219/219 [==============================] - 0s 60us/step - loss: 0.1717 - acc: 0.9041 - val_loss: 0.2085 - val_acc: 0.9324\n",
            "Epoch 54/100\n",
            "219/219 [==============================] - 0s 52us/step - loss: 0.1724 - acc: 0.9178 - val_loss: 0.2089 - val_acc: 0.9324\n",
            "Epoch 55/100\n",
            "219/219 [==============================] - 0s 59us/step - loss: 0.1716 - acc: 0.8995 - val_loss: 0.2102 - val_acc: 0.9324\n",
            "Epoch 56/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1742 - acc: 0.8950 - val_loss: 0.2105 - val_acc: 0.9324\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - 0s 53us/step - loss: 0.1714 - acc: 0.8904 - val_loss: 0.2111 - val_acc: 0.9459\n",
            "Epoch 58/100\n",
            "219/219 [==============================] - 0s 78us/step - loss: 0.1652 - acc: 0.9224 - val_loss: 0.2107 - val_acc: 0.9324\n",
            "Epoch 59/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1719 - acc: 0.9132 - val_loss: 0.2111 - val_acc: 0.9324\n",
            "Epoch 60/100\n",
            "219/219 [==============================] - 0s 38us/step - loss: 0.1688 - acc: 0.9041 - val_loss: 0.2109 - val_acc: 0.9324\n",
            "Epoch 61/100\n",
            "219/219 [==============================] - 0s 58us/step - loss: 0.1668 - acc: 0.8950 - val_loss: 0.2112 - val_acc: 0.9324\n",
            "Epoch 62/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1687 - acc: 0.8950 - val_loss: 0.2112 - val_acc: 0.9324\n",
            "Epoch 63/100\n",
            "219/219 [==============================] - 0s 54us/step - loss: 0.1646 - acc: 0.9087 - val_loss: 0.2106 - val_acc: 0.9459\n",
            "Epoch 64/100\n",
            "219/219 [==============================] - 0s 38us/step - loss: 0.1659 - acc: 0.9224 - val_loss: 0.2110 - val_acc: 0.9459\n",
            "Epoch 65/100\n",
            "219/219 [==============================] - 0s 39us/step - loss: 0.1659 - acc: 0.9041 - val_loss: 0.2108 - val_acc: 0.9459\n",
            "Epoch 66/100\n",
            "219/219 [==============================] - 0s 41us/step - loss: 0.1617 - acc: 0.9178 - val_loss: 0.2117 - val_acc: 0.9459\n",
            "Epoch 67/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1612 - acc: 0.9224 - val_loss: 0.2125 - val_acc: 0.9324\n",
            "Epoch 68/100\n",
            "219/219 [==============================] - 0s 56us/step - loss: 0.1657 - acc: 0.9224 - val_loss: 0.2129 - val_acc: 0.9324\n",
            "Epoch 69/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1633 - acc: 0.9224 - val_loss: 0.2130 - val_acc: 0.9459\n",
            "Epoch 70/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1623 - acc: 0.9224 - val_loss: 0.2142 - val_acc: 0.9324\n",
            "Epoch 71/100\n",
            "219/219 [==============================] - 0s 43us/step - loss: 0.1687 - acc: 0.8950 - val_loss: 0.2148 - val_acc: 0.9324\n",
            "Epoch 72/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1653 - acc: 0.9224 - val_loss: 0.2151 - val_acc: 0.9324\n",
            "Epoch 73/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1624 - acc: 0.9087 - val_loss: 0.2156 - val_acc: 0.9324\n",
            "Epoch 74/100\n",
            "219/219 [==============================] - 0s 89us/step - loss: 0.1600 - acc: 0.8950 - val_loss: 0.2164 - val_acc: 0.9459\n",
            "Epoch 75/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1581 - acc: 0.9132 - val_loss: 0.2174 - val_acc: 0.9459\n",
            "Epoch 76/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1653 - acc: 0.9178 - val_loss: 0.2181 - val_acc: 0.9459\n",
            "Epoch 77/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1668 - acc: 0.8950 - val_loss: 0.2193 - val_acc: 0.9324\n",
            "Epoch 78/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1626 - acc: 0.9269 - val_loss: 0.2206 - val_acc: 0.9189\n",
            "Epoch 79/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1632 - acc: 0.8950 - val_loss: 0.2208 - val_acc: 0.9189\n",
            "Epoch 80/100\n",
            "219/219 [==============================] - 0s 48us/step - loss: 0.1656 - acc: 0.9087 - val_loss: 0.2205 - val_acc: 0.9324\n",
            "Epoch 81/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1614 - acc: 0.8858 - val_loss: 0.2199 - val_acc: 0.9459\n",
            "Epoch 82/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1621 - acc: 0.9132 - val_loss: 0.2183 - val_acc: 0.9324\n",
            "Epoch 83/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1623 - acc: 0.9269 - val_loss: 0.2170 - val_acc: 0.9459\n",
            "Epoch 84/100\n",
            "219/219 [==============================] - 0s 50us/step - loss: 0.1585 - acc: 0.9132 - val_loss: 0.2159 - val_acc: 0.9459\n",
            "Epoch 85/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1584 - acc: 0.9224 - val_loss: 0.2161 - val_acc: 0.9459\n",
            "Epoch 86/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1579 - acc: 0.9224 - val_loss: 0.2159 - val_acc: 0.9459\n",
            "Epoch 87/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1586 - acc: 0.9132 - val_loss: 0.2170 - val_acc: 0.9459\n",
            "Epoch 88/100\n",
            "219/219 [==============================] - 0s 57us/step - loss: 0.1578 - acc: 0.9269 - val_loss: 0.2191 - val_acc: 0.9459\n",
            "Epoch 89/100\n",
            "219/219 [==============================] - 0s 68us/step - loss: 0.1601 - acc: 0.9178 - val_loss: 0.2212 - val_acc: 0.9459\n",
            "Epoch 90/100\n",
            "219/219 [==============================] - 0s 56us/step - loss: 0.1582 - acc: 0.9087 - val_loss: 0.2222 - val_acc: 0.9459\n",
            "Epoch 91/100\n",
            "219/219 [==============================] - 0s 53us/step - loss: 0.1637 - acc: 0.9132 - val_loss: 0.2233 - val_acc: 0.9459\n",
            "Epoch 92/100\n",
            "219/219 [==============================] - 0s 44us/step - loss: 0.1592 - acc: 0.9132 - val_loss: 0.2234 - val_acc: 0.9459\n",
            "Epoch 93/100\n",
            "219/219 [==============================] - 0s 63us/step - loss: 0.1582 - acc: 0.9361 - val_loss: 0.2221 - val_acc: 0.9324\n",
            "Epoch 94/100\n",
            "219/219 [==============================] - 0s 56us/step - loss: 0.1597 - acc: 0.9178 - val_loss: 0.2207 - val_acc: 0.9459\n",
            "Epoch 95/100\n",
            "219/219 [==============================] - 0s 49us/step - loss: 0.1559 - acc: 0.9087 - val_loss: 0.2197 - val_acc: 0.9459\n",
            "Epoch 96/100\n",
            "219/219 [==============================] - 0s 71us/step - loss: 0.1652 - acc: 0.8904 - val_loss: 0.2191 - val_acc: 0.9459\n",
            "Epoch 97/100\n",
            "219/219 [==============================] - 0s 46us/step - loss: 0.1571 - acc: 0.9087 - val_loss: 0.2183 - val_acc: 0.9459\n",
            "Epoch 98/100\n",
            "219/219 [==============================] - 0s 55us/step - loss: 0.1608 - acc: 0.9132 - val_loss: 0.2181 - val_acc: 0.9459\n",
            "Epoch 99/100\n",
            "219/219 [==============================] - 0s 50us/step - loss: 0.1587 - acc: 0.9178 - val_loss: 0.2180 - val_acc: 0.9459\n",
            "Epoch 100/100\n",
            "219/219 [==============================] - 0s 47us/step - loss: 0.1604 - acc: 0.9178 - val_loss: 0.2189 - val_acc: 0.9459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91fb580b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMsVchNblDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "172d7c89-fdac-4057-8d0d-70785f6b0d7a"
      },
      "source": [
        "imagem_teste = np.expand_dims(X_test[2], axis = 0)\n",
        "print(X_test[2])\n",
        "print(y_test[2])\n",
        "if classificador.predict(imagem_teste) > 0.5:\n",
        "  print(\"homer\")\n",
        "else:\n",
        "  print(\"bart\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.12615    7.112821   2.0850525  0.         0.         0.06664551]\n",
            "0\n",
            "bart\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}